{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "843f03bf-0353-4822-9ab8-4060bee7637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import *\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "def make_mapping_node(amap, input_name, output_name, keys='strings', values='int64s'):\n",
    "    valid_key_values = ['strings', 'int64s', 'floats']\n",
    "    assert keys in valid_key_values and values in valid_key_values, f'Keys or Values not in valid set of {valid_key_values}'\n",
    "    other_inps = {f'keys_{keys}': amap.keys(), f'values_{values}': amap.values()}\n",
    "    return onnx.helper.make_node('LabelEncoder', inputs=[input_name], outputs=[output_name], domain='ai.onnx.ml', **other_inps)\n",
    "    \n",
    "def replace_node_value(input_output, new_node_value, replace_node_name):\n",
    "    existing_node = list(filter(lambda x: x.name == replace_node_name, input_output))[0]\n",
    "    input_output.remove(existing_node)\n",
    "    input_output.append(new_node_value)\n",
    "    \n",
    "\n",
    "class MLTModel(nn.Module):\n",
    "    def __init__(self, it2ind_mapping: Dict[str, int], vectors):\n",
    "        super(MLTModel, self).__init__()\n",
    "        n_items = len(vectors)\n",
    "        n_factors = len(vectors[0])\n",
    "        self.emb = nn.Embedding(n_items, n_factors, _weight=torch.from_numpy(vectors))\n",
    "        self.it2ind = it2ind_mapping\n",
    "        self.ind2it = {v:k for k,v in self.it2ind.items()}\n",
    "    \n",
    "    # model forward pass\n",
    "    def forward(self, ind: torch.Tensor, size: int = 5)-> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        u = self.emb(ind)\n",
    "        scores = u @ self.emb.weight.t()\n",
    "        s, i = scores.topk(size)\n",
    "        return s.squeeze(), i.squeeze()\n",
    "    \n",
    "    # most of the export code is here to map strings in and out of the network\n",
    "    # which is not supported by default when exporting a PyTorch graph --> ONNX\n",
    "    def add_onnx_mappings(self, path, op_set):\n",
    "        import onnx\n",
    "        om = onnx.load(path)\n",
    "        \n",
    "        #TODO obviously simplify this, and possibly make it not neccessary to think about for the modeller.\n",
    "        # Map input\n",
    "        in_node_value = onnx.helper.make_tensor_value_info('contentId', onnx.TensorProto.STRING, [None])\n",
    "        replace_node_name = 'contentId_ind'\n",
    "        n = make_mapping_node(self.it2ind, in_node_value.name, replace_node_name)\n",
    "        om.graph.node.insert(0, n)\n",
    "        replace_node_value(om.graph.input, in_node_value, replace_node_name)\n",
    "        \n",
    "        # Map output\n",
    "        out_node_value = onnx.helper.make_tensor_value_info('contentIdd', onnx.TensorProto.STRING, [None])\n",
    "        replace_node_name = 'indices'\n",
    "        n = make_mapping_node(self.ind2it, replace_node_name, out_node_value.name, keys='int64s', values='strings')\n",
    "        om.graph.node.append(n)\n",
    "        replace_node_value(om.graph.output, out_node_value, replace_node_name)\n",
    "        \n",
    "        # finalize model\n",
    "        model = onnx.helper.make_model(om.graph, opset_imports=[onnx.helper.make_opsetid('ai.onnx.ml', 2), onnx.helper.make_opsetid('', op_set)])\n",
    "        onnx.checker.check_model(model)\n",
    "        onnx.save(model, path)\n",
    "        \n",
    "    \n",
    "    def export(self, path='model.onnx', onnx_op_set=16):\n",
    "        input_names = ['contentId_ind', 'size']\n",
    "        output_names = ['scores', 'indices'] # this should be a convention? \n",
    "        # Dynamic axes does nothing since we re-export the model atm.\n",
    "        dynamic_axes = {name: [0] for name in output_names}\n",
    "        jit_model = torch.jit.script(self)\n",
    "        dummy_input = (torch.ones(1).long(), 3)\n",
    "        dummy_input = tuple(1 for _ in input_names)\n",
    "        torch.onnx.export(jit_model, dummy_input, path, input_names=input_names, output_names=output_names, dynamic_axes=dynamic_axes, verbose=True, opset_version=onnx_op_set)\n",
    "        self.add_onnx_mappings(path, onnx_op_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ce677fe6-fc40-4e78-b81e-f2332405efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO actually load real weights from a generated model\n",
    "#TODO add user --> item\n",
    "#TODO add dynamic_axes to final output model, to stop warning\n",
    "#TODO meta level error handling. etc, having size>num_items_in_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c93b0760-ca09-4970-9ae2-81c7c9c12da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "om = onnx.load('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "578bf10e-90c2-4468-9ddf-12c37e9fc662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'', 'LabelEncoder'},\n",
       " {'Gather', 'Gather_0'},\n",
       " {'MatMul', 'MatMul_1'},\n",
       " {'Constant', 'Constant_2'},\n",
       " {'Reshape', 'Reshape_3'},\n",
       " {'TopK', 'TopK_4'},\n",
       " {'Squeeze', 'Squeeze_5'},\n",
       " {'Squeeze', 'Squeeze_6'},\n",
       " {'', 'LabelEncoder'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: {x.name, x.op_type}, om.graph.node))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f944d2f4-9e16-411d-ae78-28c35c1176b4",
   "metadata": {},
   "source": [
    "# Use some real data\n",
    "Pull down a model, and import the newline-delimited json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "97610722-12a9-4d19-96ac-7e759ae3cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/model.json', 'r') as f:\n",
    "    rows = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d0944c43-3e9f-497a-b793-bdfa0c7baa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_model_data = {x['contentId']: x['factors'] for x in rows}\n",
    "\n",
    "vectors = np.array([x for x in real_model_data.values()])\n",
    "name2ind = {n:i for i, n in enumerate(real_model_data.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d67d03b5-ba3d-4d0a-bdc4-41f31935a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLTModel(name2ind, vectors)\n",
    "model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f83ce439-3fb4-438b-989f-65d62eef2d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just make sure all or ducks are in a row\n",
    "np.isclose(vectors[0], np.array(rows[0]['factors'])).all() , np.isclose(model.emb.weight[0].detach().numpy(), np.array(rows[0]['factors'])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "68db7569-15c2-4d92-a5f5-8198f1b00d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lover', 'lunsj', 'mamma', 'marit', 'match']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(name2ind.keys())[110:115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "61663614-50d5-4c80-95e6-211a91a33652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ski-vm-junior-og-u23': 1.0000000000000002,\n",
       " 'dama-til': 0.999999999638621,\n",
       " 'KOIF43007811': 0.9999999995384318,\n",
       " 'KMNO10008822': 0.9999999992626512,\n",
       " 'KOIF75000417': 0.9999999976467383,\n",
       " 'friidrett-nm': 0.9999999963539263,\n",
       " 'verdens-beste-landslag': 0.9999999922260039,\n",
       " 'kriger': 0.9999999904107656,\n",
       " 'lunsj': 0.9999999903992889,\n",
       " 'der-ingen-skulle-tru-at-nokon-kunne-bu': 0.9999999876724911}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 13:28:00.150713884 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {10} for output scores\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession('model.onnx')\n",
    "inp = np.array([\"ski-vm-junior-og-u23\"])\n",
    "ort_inputs = {'contentId': inp, 'size': np.ones(1, dtype=np.int64) * 10}\n",
    "res = ort_session.run(None, ort_inputs)\n",
    "{n:s for n, s in zip(res[1], res[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447aeb77-42c4-46ca-9bdf-ea0afe649818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
