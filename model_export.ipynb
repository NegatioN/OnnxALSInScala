{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "752d1405-cd81-490f-9167-3cf84bb90287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import *\n",
    "\n",
    "#TODO actually load real weights from a generated model\n",
    "class ALSModel(nn.Module):\n",
    "    def __init__(self, n_items: int, n_factors: int):\n",
    "        super(ALSModel, self).__init__()\n",
    "        #TODO add user --> item\n",
    "        self.emb = nn.Embedding(n_items, n_factors)\n",
    "        self.it2ind = {str(i): i for i in range(n_items)}# TODO use real values\n",
    "        self.ind2it = {v:k for k,v in self.it2ind.items()}\n",
    "        \n",
    "    def map_out(self, scores: torch.Tensor, indices: torch.Tensor) -> Dict[str, float]:\n",
    "        inds: List[int] = indices.squeeze().tolist()\n",
    "        scorez: List[float] = scores.squeeze().tolist()\n",
    "        return {self.ind2it[i]: s for i, s in zip(inds, scorez)}\n",
    "    \n",
    "    #def forward(self, ind: torch.Tensor, size: int = 30)-> Dict[str, float]:\n",
    "    #def forward(self, ind: torch.Tensor)-> torch.Tensor:\n",
    "    def forward(self, ind: torch.Tensor, size: int = 5)-> torch.Tensor:\n",
    "        #ind = torch.tensor([self.it2ind[inp]]).long()\n",
    "        u = self.emb(ind)\n",
    "        scores = u @ self.emb.weight.t()\n",
    "        s, i = scores.topk(size)\n",
    "        #return self.map_out(s, i)\n",
    "        return s.squeeze()\n",
    "        \n",
    "        \n",
    "n_items, n_factors = (10000, 128)     \n",
    "m = ALSModel(n_items, n_factors)\n",
    "m2 = torch.jit.script(m)\n",
    "    \n",
    "#TODO can we actually map strings and stuff in ONNX? It seems like we cant???\n",
    "#m(\"5\", size=5), m2(\"5\", size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bf787bc-82ec-4c17-beff-8714bc898988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([118.0973,  37.7835,  36.9943,  35.9663,  35.9311],\n",
       "        grad_fn=<SqueezeBackward0>),\n",
       " torch.return_types.sort(\n",
       " values=tensor([118.0973,  37.7835,  36.9943,  35.9663,  35.9311],\n",
       "        grad_fn=<SortBackward0>),\n",
       " indices=tensor([0, 1, 2, 3, 4])))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = m2(torch.ones(1).long())\n",
    "o, o.sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "197e4cde-b0b0-4d2a-b95a-50543a6d98b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%ind.1 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %size.1 : Long(device=cpu),\n",
      "      %emb.weight : Float(10000, 128, strides=[128, 1], requires_grad=0, device=cpu),\n",
      "      %11 : Float(128, 10000, strides=[1, 128], requires_grad=0, device=cpu)):\n",
      "  %u : Float(1, 128, strides=[128, 1], device=cpu) = onnx::Gather(%emb.weight, %ind.1) # /home/n651042/micromamba/envs/attention/lib/python3.10/site-packages/torch/nn/functional.py:2183:11\n",
      "  %scores : Float(1, 10000, strides=[10000, 1], device=cpu) = onnx::MatMul(%u, %11) # /tmp/ipykernel_12857/2553407528.py:25:17\n",
      "  %6 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /tmp/ipykernel_12857/2553407528.py:26:15\n",
      "  %7 : Long(1, strides=[1], device=cpu) = onnx::Reshape[allowzero=0](%size.1, %6) # /tmp/ipykernel_12857/2553407528.py:26:15\n",
      "  %s : Float(*, *, device=cpu), %i : Long(*, *, device=cpu) = onnx::TopK[axis=-1, largest=1, sorted=1](%scores, %7) # /tmp/ipykernel_12857/2553407528.py:26:15\n",
      "  %10 : Float(3, strides=[1], requires_grad=1, device=cpu) = onnx::Squeeze(%s) # /tmp/ipykernel_12857/2553407528.py:28:15\n",
      "  return (%10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#x = (torch.ones(1).long())\n",
    "x = (torch.ones(1).long(), 3)\n",
    "file_path = \"data/model.onnx\"\n",
    "torch.onnx.export(m2, x, file_path, verbose=True, opset_version=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50bc556b-08d6-44d4-a6a3-c46e09c582b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "# ensure a valid onnx file\n",
    "onnx.checker.check_model(onnx.load(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09324e29-97b6-4a71-8598-1fac0ea6bf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([132.13054 ,  40.181793,  40.153183,  39.523598,  38.097862,\n",
      "        37.84709 ,  37.330074,  36.924046,  36.715164,  36.378918,\n",
      "        35.684757,  35.634724,  35.04893 ,  34.54045 ,  34.072304,\n",
      "        33.694126,  33.0558  ,  32.82387 ,  32.82374 ,  32.617374,\n",
      "        32.533703,  32.441418,  32.32119 ,  31.737667,  31.354448,\n",
      "        30.98542 ,  30.5975  ,  30.574152,  30.384832,  30.371317,\n",
      "        30.342276,  30.330914,  30.131212,  30.08917 ,  30.084301,\n",
      "        30.064453,  29.63688 ,  29.489979,  29.363363,  29.354372,\n",
      "        29.288212,  29.18877 ,  29.18855 ,  29.039358,  29.004469,\n",
      "        28.882124,  28.814892,  28.809755,  28.714895,  28.598053,\n",
      "        28.595556,  28.589615,  28.504133,  28.389652,  28.378061,\n",
      "        28.31546 ,  28.30276 ,  28.286125,  28.201939,  28.05688 ,\n",
      "        27.745224,  27.590948,  27.58031 ,  27.515045,  27.487463,\n",
      "        27.479776,  27.441105,  27.385202,  27.330118,  27.30194 ,\n",
      "        27.231031,  27.118498,  27.115707,  27.100737,  27.089224,\n",
      "        27.013617,  26.972506,  26.963326,  26.93962 ,  26.83654 ,\n",
      "        26.761066,  26.687544,  26.678358,  26.619028,  26.606264,\n",
      "        26.568981,  26.501375,  26.431355,  26.426243,  26.423584,\n",
      "        26.420658,  26.410475,  26.364904,  26.292177,  26.071985,\n",
      "        26.059288,  26.031431,  25.780512,  25.753046], dtype=float32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 11:22:12.099381850 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {3} does not match actual shape of {99} for output 10\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "# sanity test outputs\n",
    "ort_session = onnxruntime.InferenceSession(file_path)\n",
    "inp = np.ones(1, dtype=np.int64) * 99\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: inp, ort_session.get_inputs()[1].name: inp}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "print(ort_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d162f4db-fd25-4912-acb2-0733445f0323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'size.1'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_session.get_inputs()[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2baaf4-aa25-4e34-95ba-72620e863b30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
