{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "843f03bf-0353-4822-9ab8-4060bee7637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import *\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "def make_mapping_node(amap, input_name, output_name, keys='strings', values='int64s'):\n",
    "    valid_key_values = ['strings', 'int64s', 'floats']\n",
    "    assert keys in valid_key_values and values in valid_key_values, f'Keys or Values not in valid set of {valid_key_values}'\n",
    "    other_inps = {f'keys_{keys}': amap.keys(), f'values_{values}': amap.values()}\n",
    "    n = onnx.helper.make_node('LabelEncoder', inputs=[input_name], outputs=[output_name], domain='ai.onnx.ml', **other_inps)\n",
    "    return n\n",
    "    \n",
    "\n",
    "class MLTModel(nn.Module):\n",
    "    def __init__(self, n_items: int, n_factors: int):\n",
    "        super(MLTModel, self).__init__()\n",
    "        self.emb = nn.Embedding(n_items, n_factors)\n",
    "        self.it2ind = {str(i): i for i in range(n_items)}\n",
    "        self.ind2it = {v:k for k,v in self.it2ind.items()}\n",
    "    \n",
    "    def forward(self, ind: torch.Tensor, size: int = 5)-> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        u = self.emb(ind)\n",
    "        scores = u @ self.emb.weight.t()\n",
    "        s, i = scores.topk(size)\n",
    "        return s.squeeze(), i.squeeze()\n",
    "    \n",
    "    # most of the export code is here to map strings in and out of the network\n",
    "    # which is not supported by default when exporting a PyTorch graph --> ONNX\n",
    "    def add_onnx_mappings(self, path, op_set):\n",
    "        import onnx\n",
    "        om = onnx.load(path)\n",
    "        \n",
    "        #TODO obviously simplify this, and possibly make it not neccessary to think about for the modeller.\n",
    "        # Map input\n",
    "        replace_node_name = 'contentId_ind'\n",
    "        in_node_value = onnx.helper.make_tensor_value_info('contentId', onnx.TensorProto.STRING, [None])\n",
    "        n = make_mapping_node(self.it2ind, in_node_value.name, replace_node_name)\n",
    "\n",
    "        existing_node = list(filter(lambda x: x.name == replace_node_name, om.graph.input))[0]\n",
    "        om.graph.input.remove(existing_node)\n",
    "        om.graph.input.append(in_node_value)\n",
    "        # TODO something that sorts the graph nodes? Since they need to be placed in the correct position.\n",
    "        om.graph.node.insert(0, n)\n",
    "        \n",
    "        # Map output\n",
    "        out_node_value = onnx.helper.make_tensor_value_info('contentId', onnx.TensorProto.STRING, [None])\n",
    "        replace_node_name = 'indices'\n",
    "        n = make_mapping_node(self.ind2it, replace_node_name, out_node_value.name, keys='int64s', values='strings')\n",
    "        \n",
    "        existing_node = list(filter(lambda x: x.name == replace_node_name, om.graph.output))[0]\n",
    "        om.graph.output.remove(existing_node)\n",
    "        om.graph.output.append(out_node_value)\n",
    "        om.graph.node.append(n)\n",
    "        \n",
    "        # finalize model\n",
    "        model = onnx.helper.make_model(om.graph, opset_imports=[onnx.helper.make_opsetid('ai.onnx.ml', 2), onnx.helper.make_opsetid('', op_set)])\n",
    "        onnx.checker.check_model(model)\n",
    "        onnx.save(model, path)\n",
    "        \n",
    "    \n",
    "    def export(self, path='model.onnx', onnx_op_set=16):\n",
    "        input_names = ['contentId_ind', 'size']\n",
    "        output_names = ['scores', 'indices'] # this should be a convention? \n",
    "        # Dynamic axes does nothing since we re-export the model atm.\n",
    "        dynamic_axes = {name: [0] for name in output_names}\n",
    "        jit_model = torch.jit.script(self)\n",
    "        dummy_input = (torch.ones(1).long(), 3)\n",
    "        dummy_input = tuple(1 for _ in input_names)\n",
    "        torch.onnx.export(jit_model, dummy_input, path, input_names=input_names, output_names=output_names, dynamic_axes=dynamic_axes, verbose=True, opset_version=onnx_op_set)\n",
    "        self.add_onnx_mappings(path, onnx_op_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7ac8e87-842c-4676-aaf4-9f6abef38d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = MLTModel(10000, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98546d5f-2e16-48d7-9c11-2f4b608c4d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%contentId_ind : Long(requires_grad=0, device=cpu),\n",
      "      %size : Long(device=cpu),\n",
      "      %emb.weight : Float(10000, 128, strides=[128, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_12 : Float(128, 10000, strides=[1, 128], requires_grad=0, device=cpu)):\n",
      "  %u : Float(128, strides=[1], device=cpu) = onnx::Gather[onnx_name=\"Gather_0\"](%emb.weight, %contentId_ind) # /home/n651042/micromamba/envs/onnx/lib/python3.10/site-packages/torch/nn/functional.py:2199:11\n",
      "  %scores.1 : Float(10000, strides=[1], device=cpu) = onnx::MatMul[onnx_name=\"MatMul_1\"](%u, %onnx::MatMul_12) # /tmp/ipykernel_5861/1164184637.py:26:17\n",
      "  %onnx::Reshape_6 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"Constant_2\"]() # /tmp/ipykernel_5861/1164184637.py:27:15\n",
      "  %onnx::TopK_7 : Long(1, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"Reshape_3\"](%size, %onnx::Reshape_6) # /tmp/ipykernel_5861/1164184637.py:27:15\n",
      "  %s : Float(*, device=cpu), %i : Long(*, device=cpu) = onnx::TopK[axis=-1, largest=1, sorted=1, onnx_name=\"TopK_4\"](%scores.1, %onnx::TopK_7) # /tmp/ipykernel_5861/1164184637.py:27:15\n",
      "  %scores : Float(requires_grad=1, device=cpu) = onnx::Squeeze[onnx_name=\"Squeeze_5\"](%s) # /tmp/ipykernel_5861/1164184637.py:28:15\n",
      "  %indices : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"Squeeze_6\"](%i) # /tmp/ipykernel_5861/1164184637.py:28:28\n",
      "  return (%scores, %indices)\n",
      "\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "Graph must be in single static assignment (SSA) form, however 'contentId' has been used as output names multiple times.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [60], line 73\u001b[0m, in \u001b[0;36mMLTModel.export\u001b[0;34m(self, path, onnx_op_set)\u001b[0m\n\u001b[1;32m     71\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m input_names)\n\u001b[1;32m     72\u001b[0m torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mexport(jit_model, dummy_input, path, input_names\u001b[38;5;241m=\u001b[39minput_names, output_names\u001b[38;5;241m=\u001b[39moutput_names, dynamic_axes\u001b[38;5;241m=\u001b[39mdynamic_axes, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, opset_version\u001b[38;5;241m=\u001b[39monnx_op_set)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_onnx_mappings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monnx_op_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [60], line 60\u001b[0m, in \u001b[0;36mMLTModel.add_onnx_mappings\u001b[0;34m(self, path, op_set)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# finalize model\u001b[39;00m\n\u001b[1;32m     59\u001b[0m model \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mhelper\u001b[38;5;241m.\u001b[39mmake_model(om\u001b[38;5;241m.\u001b[39mgraph, opset_imports\u001b[38;5;241m=\u001b[39m[onnx\u001b[38;5;241m.\u001b[39mhelper\u001b[38;5;241m.\u001b[39mmake_opsetid(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mai.onnx.ml\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m), onnx\u001b[38;5;241m.\u001b[39mhelper\u001b[38;5;241m.\u001b[39mmake_opsetid(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, op_set)])\n\u001b[0;32m---> 60\u001b[0m \u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchecker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m onnx\u001b[38;5;241m.\u001b[39msave(model, path)\n",
      "File \u001b[0;32m~/micromamba/envs/onnx/lib/python3.10/site-packages/onnx/checker.py:106\u001b[0m, in \u001b[0;36mcheck_model\u001b[0;34m(model, full_check)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mgetsizeof(protobuf_string) \u001b[38;5;241m>\u001b[39m MAXIMUM_PROTOBUF:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis protobuf of onnx model is too large (>2GB). Call check_model with model path instead.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m \u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotobuf_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_check:\n\u001b[1;32m    108\u001b[0m     onnx\u001b[38;5;241m.\u001b[39mshape_inference\u001b[38;5;241m.\u001b[39minfer_shapes(model, check_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, strict_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValidationError\u001b[0m: Graph must be in single static assignment (SSA) form, however 'contentId' has been used as output names multiple times."
     ]
    }
   ],
   "source": [
    "a.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a358af44-ff71-4c06-a358-b03af049af7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 12:26:59.361970707 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {} does not match actual shape of {5} for output scores\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([154.96382 ,  46.32555 ,  42.35973 ,  41.462833,  41.073437],\n",
       "       dtype=float32),\n",
       " array(['5', '9418', '9878', '7925', '5728'], dtype=object)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession('model.onnx')\n",
    "inp = np.array([\"5\"])\n",
    "ort_inputs = {'contentId': inp, 'size': np.ones(1, dtype=np.int64) * 5}\n",
    "ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce677fe6-fc40-4e78-b81e-f2332405efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO actually load real weights from a generated model\n",
    "#TODO add user --> item\n",
    "#TODO add dynamic_axes to final output model, to stop warning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
